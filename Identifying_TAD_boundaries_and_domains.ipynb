{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiCExplorer pipeline\n",
    "\n",
    "**Versions**  \n",
    "bwa: 0.7.13  \n",
    "samtools: 1.3.1  \n",
    "java: 1.8.0_211  \n",
    "HiC_explorer: 2.2  \n",
    "Trimmomatic: 0.39  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=main    # Partition (job queue)\n",
    "#SBATCH --job-name=HiC         # Assign an 8-character name to your job, no spaces\n",
    "#SBATCH --nodes=1                # Number of compute nodes\n",
    "#SBATCH --ntasks=1               # Processes (usually = cores) on each node\n",
    "#SBATCH --cpus-per-task=28       # Threads per process (or per core)\n",
    "#SBATCH --export=ALL             # Export you current environment settings to the job environment\n",
    "#SBATCH --time=12:00:00\n",
    "#SBATCH --mem=128000\n",
    "#SBATCH --output=slurm-%A_%a.out\n",
    "#SBATCH --array=1-10\n",
    "\n",
    "DIR=/dup_*\n",
    "REF=/references\n",
    "\n",
    "BIN=5000\n",
    "\n",
    "module load bwa\n",
    "module load samtools\n",
    "module load java\n",
    "\n",
    "samtools faidx $REF \n",
    "bwa index $REF \n",
    "\n",
    "cd $DIR\n",
    "cp /pkg/Trimmomatic-0.39/adapters/TruSeq3-PE.fa $DIR/.\n",
    "\n",
    "# TRIM READS: will produce files ending in _1P.fastq.gz, _2P.fastq.gz, _1U.fastq.gz, and _2U.fastq.gz\n",
    "\n",
    "java -jar /pkg/Trimmomatic-0.39/trimmomatic-0.39.jar PE $SLURM_ARRAY_TASK_ID.R1.fastq.gz $SLURM_ARRAY_TASK_ID.R2.fastq.gz -threads 28 -baseout $SLURM_ARRAY_TASK_ID.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:10 TRAILING:10 SLIDINGWINDOW:4:15 MINLEN:36\n",
    "\n",
    "# Perl script takes output from trimmomatic and creates two new files: split_P1.fa and split_P2.fa\n",
    "perl /combined_cut_nt.pl $SLURM_ARRAY_TASK_ID\\_1P.fastq.gz $SLURM_ARRAY_TASK_ID\\_2P.fastq.gz $SLURM_ARRAY_TASK_ID\\_1U.fastq.gz $SLURM_ARRAY_TASK_ID\\_2U.fastq.gz $SLURM_ARRAY_TASK_ID \n",
    "\n",
    "# ALIGN split_P1.fa and split_P2.fa WITH BWA\n",
    "\n",
    "bwa mem -t 28 -A1 -B4 -E50 -L0 $REF split_$SLURM_ARRAY_TASK_ID.P1.fa 2>mate_$SLURM_ARRAY_TASK_ID\\_R1.log | samtools view -Shb - > $SLURM_ARRAY_TASK_ID.R1.bam\n",
    "bwa mem -t 28 -A1 -B4 -E50 -L0 $REF split_$SLURM_ARRAY_TASK_ID.P2.fa 2>mate_$SLURM_ARRAY_TASK_ID\\_R2.log | samtools view -Shb - > $SLURM_ARRAY_TASK_ID.R2.bam\n",
    "\n",
    "# Delete split files\n",
    "rm split_$SLURM_ARRAY_TASK_ID.P*.fa\n",
    "\n",
    "# BUILD MATRIX\n",
    "hicBuildMatrix --samFiles $SLURM_ARRAY_TASK_ID.R1.bam $SLURM_ARRAY_TASK_ID.R2.bam --binSize $BIN --outBam $SLURM_ARRAY_TASK_ID\\_hicMat.bam --minMappingQuality 20 -o $SLURM_ARRAY_TASK_ID\\_$BIN\\bp.h5 --QCfolder $SLURM_ARRAY_TASK_ID\\_hicQC >& $SLURM_ARRAY_TASK_ID.buildmatrix.log\n",
    "\n",
    "# CORRECT MATRIX\n",
    "\n",
    "hicCorrectMatrix diagnostic_plot -m $SLURM_ARRAY_TASK_ID\\_$BIN\\bp.h5 --plotName $SLURM_ARRAY_TASK_ID.diagnostic_plot.png >& $SLURM_ARRAY_TASK_ID.plot.log\n",
    "hicCorrectMatrix correct --filterThreshold -2 2 --perchr -m $SLURM_ARRAY_TASK_ID\\_$BIN\\bp.h5 -o $SLURM_ARRAY_TASK_ID\\_hic_corrected_matrix.h5 >& $SLURM_ARRAY_TASK_ID.correct_matrix.log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find TADs in replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=main    # Partition (job queue)\n",
    "#SBATCH --job-name=findtads         # Assign an 8-character name to your job, no spaces\n",
    "#SBATCH --nodes=1                # Number of compute nodes\n",
    "#SBATCH --ntasks=1               # Processes (usually = cores) on each node\n",
    "#SBATCH --cpus-per-task=28       # Threads per process (or per core)\n",
    "#SBATCH --export=ALL             # Export you current environment settings to the job environment\n",
    "#SBATCH --time=12:00:00\n",
    "#SBATCH --mem=128000\n",
    "#SBATCH --output=slurm-%A_%a.out\n",
    "#SBATCH --array=\n",
    "\n",
    "BIN=5000\n",
    "\n",
    "hicFindTADs --matrix /dup_1/dmel_hic_corrected_matrix.h5 --minDepth 50000 --maxDepth 200000 --correctForMultipleTesting fdr --outPrefix ./dup_1/dmel\n",
    "hicFindTADs --matrix /dup_2/dmel_hic_corrected_matrix.h5 --minDepth 50000 --maxDepth 200000 --correctForMultipleTesting fdr --outPrefix ./dup_2/dmel\n",
    "\n",
    "hicFindTADs --matrix /dup_1/dtri_hic_corrected_matrix.h5 --minDepth 50000 --maxDepth 200000 --correctForMultipleTesting fdr --outPrefix ./dup_1/dtri\n",
    "hicFindTADs --matrix /dup_2/dtri_hic_corrected_matrix.h5 --minDepth 50000 --maxDepth 200000 --correctForMultipleTesting fdr --outPrefix ./dup_2/dtri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python script to plot and find correlation between TAD separation scores in replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statistics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = open(\"output.txt\", 'w')\n",
    "d = open(\"rep1_score.bedgraph\")\n",
    "for line in d:\n",
    "    j = line.split()\n",
    "    f = open(\"rep2_score.bedgraph\")\n",
    "    for line in f:\n",
    "        i = line.split()\n",
    "        if j[0] != i[0]:\n",
    "            continue\n",
    "        if j[1] == i[1]:\n",
    "            m.write(str(j[0]) + \"\\t\" + str(j[1]) + \"\\t\" + str(j[2]) + \"\\t\" + str(j[3]) + \"\\t\" + str(i[0]) + \"\\t\" + str(i[1]) + \"\\t\" + str(i[2]) + \"\\t\" + str(i[3]) + \"\\n\")\n",
    "    f.close()\n",
    "m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = open(\"output.txt\")\n",
    "n = list()\n",
    "o = list()\n",
    "for line in t:\n",
    "    l = line.split()\n",
    "    n.append(float(l[3]))\n",
    "    o.append(float(l[7]))\n",
    "stats.spearmanr(n,o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum replicate matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hicSumMatrices --matrices ./dup_1/$SLURM_ARRAY_TASK_ID\\_$BIN\\bp.h5 ./dup_2/$SLURM_ARRAY_TASK_ID\\_$BIN\\bp.h5 --outFileName ./summed/$SLURM_ARRAY_TASK_ID\\_$BIN\\bp.h5\n",
    "hicCorrectMatrix correct --filterThreshold -2 2 --perchr -m $SLURM_ARRAY_TASK_ID\\_$BIN\\bp.h5 -o $SLURM_ARRAY_TASK_ID\\_summed_corrected_matrix.h5 >& $SLURM_ARRAY_TASK_ID_summed_correct_matrix.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find TADs in summed matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hicFindTADs --matrix dmel_summed_corrected_matrix.h5 --minDepth 50000 --maxDepth 200000 --correctForMultipleTesting fdr --outPrefix dmel_summed\n",
    "hicFindTADs --matrix dtri_summed_corrected_matrix.h5 --minDepth 50000 --maxDepth 200000 --correctForMultipleTesting fdr --outPrefix dtri_summed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
